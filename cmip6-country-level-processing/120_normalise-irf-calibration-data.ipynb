{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "given-extent",
   "metadata": {},
   "source": [
    "# Normalise abrupt-4xCO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-temperature",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-helena",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os.path\n",
    "import re\n",
    "import traceback\n",
    "import warnings\n",
    "from concurrent.futures import as_completed, ProcessPoolExecutor\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import netcdf_scm.retractions\n",
    "import netcdf_scm.stitching\n",
    "import tqdm.autonotebook as tqdman\n",
    "\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-three",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = config.ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mighty-billion",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_CHECK = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-kingston",
   "metadata": {},
   "outputs": [],
   "source": [
    "CRUNCH_DIR = \"./{}-country-crunch-popn-weighted\".format(ID)\n",
    "STITCHED_NORMALISED_DIR = \"./{}-irf-calibration-crunch-stitched-normalised\".format(ID)\n",
    "\n",
    "MAX_WORKERS = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-charger",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p {STITCHED_NORMALISED_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-suggestion",
   "metadata": {},
   "outputs": [],
   "source": [
    "CRUNCH_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-essex",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(CRUNCH_DIR)\n",
    "abrupt4xco2_files = [\n",
    "    f\n",
    "    for f in glob.glob(os.path.join(CRUNCH_DIR, \"**\", \"*.nc\"), recursive=True)\n",
    "    if \"_abrupt-4xCO2_\" in f\n",
    "]\n",
    "# ssp_files = [f for f in glob.glob(os.path.join(CRUNCH_DIR, \"**\", \"*.nc\"), recursive=True) if \"ssp\" in f]\n",
    "display(len(abrupt4xco2_files))\n",
    "abrupt4xco2_files[:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-assault",
   "metadata": {},
   "outputs": [],
   "source": [
    "cms = set([f.split(os.sep)[6] for f in abrupt4xco2_files])\n",
    "display(len(cms))\n",
    "print(\"\\n\".join(sorted(cms)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-overall",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: move this into netcdf_scm\n",
    "retracted_ids = netcdf_scm.retractions.check_retractions(\n",
    "    [\".\".join(f.split(os.sep)[3:-1]) for f in abrupt4xco2_files],\n",
    "    esgf_query_batch_size=20,\n",
    ")\n",
    "retracted_files = []\n",
    "for i in retracted_ids:\n",
    "    retracted_dir = os.path.join(\n",
    "        CRUNCH_DIR, \"netcdf-scm-crunched\", i.replace(\".\", os.sep)\n",
    "    )\n",
    "    retracted_files_dir = os.listdir(retracted_dir)\n",
    "    assert len(retracted_files_dir) == 1\n",
    "    retracted_files.append(os.path.join(retracted_dir, retracted_files_dir[0]))\n",
    "\n",
    "sorted(retracted_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-intelligence",
   "metadata": {},
   "outputs": [],
   "source": [
    "abrupt4xco2_files = [f for f in abrupt4xco2_files if f not in retracted_files]\n",
    "display(len(abrupt4xco2_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suitable-allowance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: put useful bits of this in netCDF-SCM\n",
    "\n",
    "\n",
    "def stitch_and_normalise(\n",
    "    f, catch=True, norm_years=21, normalise=True, verbose=False, force=False\n",
    "):\n",
    "    def get_result():\n",
    "        if verbose:\n",
    "            print(f\"Loading and stitching {f}\")\n",
    "        (\n",
    "            scmrun,\n",
    "            picontrol_branching_time,\n",
    "            picontrol_file,\n",
    "        ) = netcdf_scm.stitching.get_continuous_timeseries_with_meta(\n",
    "            f, drs=\"CMIP6Output\", return_picontrol_info=normalise\n",
    "        )\n",
    "\n",
    "        variable = scmrun.get_unique_meta(\"variable\", True)\n",
    "        climate_model = scmrun.get_unique_meta(\"climate_model\", True)\n",
    "        scenario = scmrun.get_unique_meta(\"scenario\", True)\n",
    "        member_id = scmrun.get_unique_meta(\"member_id\", True)\n",
    "\n",
    "        min_time = scmrun[\"time\"].min()\n",
    "        start_year = min_time.year\n",
    "        start_month = min_time.month\n",
    "\n",
    "        max_time = scmrun[\"time\"].max()\n",
    "        end_year = max_time.year\n",
    "        end_month = max_time.month\n",
    "\n",
    "        table = os.path.basename(f).split(\"_\")[2]\n",
    "        grid = os.path.basename(f).split(\"_\")[-2]\n",
    "        out_name = f\"netcdf-scm_{variable}_Amon_{climate_model}_{scenario}_{member_id}_{grid}_{start_year}{start_month:02d}-{end_year}{end_month:02d}.nc\"\n",
    "\n",
    "        if normalise:\n",
    "            out_file = os.path.join(STITCHED_NORMALISED_DIR, out_name)\n",
    "        else:\n",
    "            out_file = os.path.join(STITCHED_DIR, out_name)\n",
    "\n",
    "        if os.path.isfile(out_file):\n",
    "            if verbose:\n",
    "                print(f\"Out file already exists: {out_file}\")\n",
    "\n",
    "            if force:\n",
    "                if verbose:\n",
    "                    print(\"Force over-writing\")\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "        if normalise:\n",
    "            if verbose:\n",
    "                print(f\"Loading {picontrol_file}\")\n",
    "\n",
    "            picontrol_scmrun = netcdf_scm.io.load_scmrun(picontrol_file)\n",
    "            picontrol_scmrun.metadata[\"netcdf-scm crunched file\"] = picontrol_file\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"Normalising using {norm_years} years\")\n",
    "\n",
    "            normaliser = netcdf_scm.normalisation.NormaliserRunningMean(\n",
    "                nyears=norm_years\n",
    "            )\n",
    "\n",
    "            out = normaliser.normalise_against_picontrol(\n",
    "                scmrun, picontrol_scmrun, picontrol_branching_time\n",
    "            )\n",
    "        else:\n",
    "            out = scmrun\n",
    "\n",
    "        out[\"grid\"] = grid\n",
    "\n",
    "        out_to_disk = out.copy()\n",
    "        out_to_disk.metadata = {\n",
    "            k.replace(\"(\", \"\").replace(\")\", \"\"): v\n",
    "            for k, v in out_to_disk.metadata.items()\n",
    "        }\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Saving to {out_file}\")\n",
    "\n",
    "        out_to_disk.to_nc(out_file)\n",
    "\n",
    "        return None\n",
    "\n",
    "    if catch:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "\n",
    "            try:\n",
    "                return get_result()\n",
    "            except Exception as exc:\n",
    "                raise ValueError(\"File failed: {}\".format(f)) from exc\n",
    "    else:\n",
    "        return get_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-receptor",
   "metadata": {},
   "outputs": [],
   "source": [
    "checker = \"./20210416-irf-calibration-crunch/netcdf-scm-crunched/CMIP6/CMIP/MOHC/UKESM1-0-LL/abrupt-4xCO2/r1i1p1f2/Amon/tas/gn/v20190406/netcdf-scm_tas_Amon_UKESM1-0-LL_abrupt-4xCO2_r1i1p1f2_gn_185001-199912.nc\"\n",
    "checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-hundred",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN_CHECK = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-lawrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CHECK:\n",
    "    import xarray as xr\n",
    "    from netcdf_scm.iris_cube_wrappers import ScmCube\n",
    "\n",
    "    def _load_helper_and_scm_cubes(path):\n",
    "        scm_cubes = {}\n",
    "\n",
    "        data = xr.open_dataset(path)\n",
    "        data.load()  # get everything in memory\n",
    "\n",
    "        # Must be kept until https://github.com/pandas-dev/pandas/issues/37071\n",
    "        # is solved\n",
    "        if data[\"time\"].encoding[\"units\"] == \"days since 1-01-01 00:00:00\":\n",
    "            data[\"time\"].encoding[\"units\"] = \"days since 0001-01-01 00:00:00\"\n",
    "\n",
    "        for _, darray in data.data_vars.items():\n",
    "            try:\n",
    "                region = darray.attrs[\"region\"]\n",
    "            except KeyError:\n",
    "                # bnds or some other unclassified variable\n",
    "                continue\n",
    "\n",
    "            if region != \"World\":\n",
    "                continue\n",
    "\n",
    "            scm_cubes[region] = ScmCube()\n",
    "\n",
    "            scm_cubes[region].cube = darray.to_iris()\n",
    "            scm_cubes[region].cube.attributes = {\n",
    "                **scm_cubes[region].cube.attributes,\n",
    "                **data.attrs,\n",
    "            }\n",
    "\n",
    "        # take any cube as base for now, not sure how to really handle this so will\n",
    "        # leave like this for now and only make this method public when I work it\n",
    "        # out...\n",
    "        loaded = list(scm_cubes.values())[0]\n",
    "\n",
    "        return loaded, scm_cubes\n",
    "\n",
    "    netcdf_scm.io._load_helper_and_scm_cubes = _load_helper_and_scm_cubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-positive",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CHECK:\n",
    "    tmp = stitch_and_normalise(checker, catch=False, verbose=True)\n",
    "    display(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-honey",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CHECK:\n",
    "    source = netcdf_scm.io.load_scmrun(checker)\n",
    "    display(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lucky-contrast",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CHECK:\n",
    "    parent_replacements = netcdf_scm.stitching.get_parent_replacements(source)\n",
    "    display(parent_replacements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "growing-harrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CHECK:\n",
    "    parent_file = netcdf_scm.stitching.get_parent_file_path(\n",
    "        checker, parent_replacements, \"CMIP6Output\"\n",
    "    )\n",
    "    display(parent_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atmospheric-flower",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CHECK:\n",
    "    parent = netcdf_scm.io.load_scmrun(parent_file)\n",
    "#     parent.metadata[\"parent_time_units\"] = \"days since 0001-01-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-absolute",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CHECK:\n",
    "    display(netcdf_scm.stitching.get_branch_time(parent, parent=True))\n",
    "    display(netcdf_scm.stitching.get_branch_time(parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "major-fisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CHECK:\n",
    "    !ncdump -h {parent_file} | grep parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-section",
   "metadata": {},
   "outputs": [],
   "source": [
    "# abrupt4xco2_files = [f for f in abrupt4xco2_files if \"UKESM\" in f]\n",
    "# abrupt4xco2_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "median-humanity",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalise = False\n",
    "normalise = True\n",
    "\n",
    "force = True\n",
    "force = False\n",
    "\n",
    "verbose = True\n",
    "verbose = False\n",
    "\n",
    "pool = ProcessPoolExecutor(max_workers=MAX_WORKERS)\n",
    "\n",
    "futures = []\n",
    "for f in tqdman.tqdm(abrupt4xco2_files):\n",
    "    futures.append(\n",
    "        pool.submit(\n",
    "            stitch_and_normalise, f, normalise=normalise, verbose=verbose, force=force\n",
    "        )\n",
    "    )\n",
    "\n",
    "all_errors = []\n",
    "errors = []\n",
    "for i, future in tqdman.tqdm(\n",
    "    enumerate(as_completed(futures, timeout=None)), total=len(futures)\n",
    "):\n",
    "    try:\n",
    "        future.result()\n",
    "    except Exception as exc:\n",
    "        errors.append(traceback.format_exc())\n",
    "\n",
    "    if i % 50 == 10 or i == len(futures) - 1:\n",
    "        print(\"\\n\\n\".join(errors))\n",
    "        all_errors += list(\n",
    "            set([v for e in errors for v in re.findall(\".*File failed: (.*.nc)\", e)])\n",
    "        )\n",
    "        #         if errors:\n",
    "        #             break\n",
    "        errors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaning-native",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-nightlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_errors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

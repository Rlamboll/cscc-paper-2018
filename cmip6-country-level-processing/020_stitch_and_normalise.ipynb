{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "inclusive-israeli",
   "metadata": {},
   "source": [
    "# Stitch and normalise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-dover",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-connectivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import glob\n",
    "import os\n",
    "import os.path\n",
    "import re\n",
    "import traceback\n",
    "import warnings\n",
    "from concurrent.futures import as_completed, ProcessPoolExecutor\n",
    "from multiprocessing import Pool\n",
    "from time import sleep\n",
    "\n",
    "import netcdf_scm.retractions\n",
    "import netcdf_scm.stitching\n",
    "import pandas as pd\n",
    "import scmdata\n",
    "import tqdm.autonotebook as tqdman\n",
    "import xarray as xr\n",
    "\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-storm",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = config.ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secondary-peninsula",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_CHECK = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-cookie",
   "metadata": {},
   "outputs": [],
   "source": [
    "CRUNCH_DIR = \"./{}-country-crunch\".format(ID)\n",
    "STITCHED_DIR = \"./{}-country-crunch-stitched\".format(ID)\n",
    "STITCHED_NORMALISED_DIR = \"./{}-country-crunch-stitched-normalised\".format(ID)\n",
    "\n",
    "CRUNCH_DIR = \"./{}-country-crunch-popn-weighted\".format(ID)\n",
    "STITCHED_DIR = \"./{}-country-crunch-stitched-popn-weighted\".format(ID)\n",
    "STITCHED_NORMALISED_DIR = (\n",
    "    \"./{}-country-crunch-stitched-normalised-popn-weighted\".format(ID)\n",
    ")\n",
    "\n",
    "MAX_WORKERS = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-automation",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p {STITCHED_DIR}\n",
    "!mkdir -p {STITCHED_NORMALISED_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-waterproof",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(CRUNCH_DIR)\n",
    "ssp_files = [\n",
    "    f\n",
    "    for f in glob.glob(os.path.join(CRUNCH_DIR, \"**\", \"*.nc\"), recursive=True)\n",
    "    if \"ssp\" in f and \"ssp245-\" not in f\n",
    "]\n",
    "# ssp_files = [f for f in glob.glob(os.path.join(CRUNCH_DIR, \"**\", \"*.nc\"), recursive=True) if \"ssp\" in f]\n",
    "display(len(ssp_files))\n",
    "ssp_files[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guided-moscow",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssp_files[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-conservative",
   "metadata": {},
   "outputs": [],
   "source": [
    "cms = set([f.split(os.sep)[6] for f in ssp_files])\n",
    "display(len(cms))\n",
    "print(\"\\n\".join(sorted(cms)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-freeware",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: move this into netcdf_scm\n",
    "retracted_ids = netcdf_scm.retractions.check_retractions(\n",
    "    [\".\".join(f.split(os.sep)[3:-1]) for f in ssp_files], esgf_query_batch_size=20\n",
    ")\n",
    "retracted_files = []\n",
    "for i in retracted_ids:\n",
    "    retracted_dir = os.path.join(\n",
    "        CRUNCH_DIR, \"netcdf-scm-crunched\", i.replace(\".\", os.sep)\n",
    "    )\n",
    "    retracted_files_dir = os.listdir(retracted_dir)\n",
    "    assert len(retracted_files_dir) == 1\n",
    "    retracted_files.append(os.path.join(retracted_dir, retracted_files_dir[0]))\n",
    "\n",
    "sorted(retracted_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-warning",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssp_files = [f for f in ssp_files if f not in retracted_files]\n",
    "display(len(ssp_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-recognition",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bcc_csm2_mr_hack_extension(picontrol, norm_years):\n",
    "    picontrol_last_year = picontrol[\"year\"].max()\n",
    "    last_nyear_mean = (\n",
    "        picontrol.filter(\n",
    "            year=range(picontrol_last_year - norm_years, picontrol_last_year + 1)\n",
    "        )\n",
    "        .timeseries()\n",
    "        .mean(axis=1)\n",
    "    )\n",
    "    last_nyear_mean.name = dt.datetime(picontrol_last_year + 1, 1, 16, 12)\n",
    "    hack_extension = pd.concat([picontrol.timeseries(), last_nyear_mean], axis=1)\n",
    "    hack_extension = scmdata.ScmRun(hack_extension)\n",
    "    hack_extension = hack_extension.interpolate(\n",
    "        hack_extension[\"time\"].tolist()\n",
    "        + [\n",
    "            dt.datetime(y, v.month, v.day, v.hour)\n",
    "            for y in range(picontrol_last_year + 1, picontrol_last_year + 400)\n",
    "            for v in hack_extension.filter(year=int(picontrol_last_year))[\n",
    "                \"time\"\n",
    "            ].tolist()\n",
    "        ][1:],\n",
    "        extrapolation_type=\"constant\",\n",
    "    )\n",
    "    hack_extension.metadata = picontrol.metadata\n",
    "\n",
    "    return hack_extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-footage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitch_and_normalise(\n",
    "    f, catch=True, norm_years=21, normalise=True, verbose=False, force=False\n",
    "):\n",
    "    def get_result():\n",
    "        if verbose:\n",
    "            print(f\"Loading and stitching {f}\")\n",
    "        (\n",
    "            scmrun,\n",
    "            picontrol_branching_time,\n",
    "            picontrol_file,\n",
    "        ) = netcdf_scm.stitching.get_continuous_timeseries_with_meta(\n",
    "            f, drs=\"CMIP6Output\", return_picontrol_info=normalise\n",
    "        )\n",
    "\n",
    "        variable = scmrun.get_unique_meta(\"variable\", True)\n",
    "        climate_model = scmrun.get_unique_meta(\"climate_model\", True)\n",
    "        scenario = scmrun.get_unique_meta(\"scenario\", True)\n",
    "        member_id = scmrun.get_unique_meta(\"member_id\", True)\n",
    "\n",
    "        min_time = scmrun[\"time\"].min()\n",
    "        start_year = min_time.year\n",
    "        start_month = min_time.month\n",
    "\n",
    "        max_time = scmrun[\"time\"].max()\n",
    "        end_year = max_time.year\n",
    "        end_month = max_time.month\n",
    "\n",
    "        table = os.path.basename(f).split(\"_\")[2]\n",
    "        grid = os.path.basename(f).split(\"_\")[-2]\n",
    "        out_name = f\"netcdf-scm_{variable}_Amon_{climate_model}_{scenario}_{member_id}_{grid}_{start_year}{start_month:02d}-{end_year}{end_month:02d}.nc\"\n",
    "\n",
    "        if normalise:\n",
    "            out_file = os.path.join(STITCHED_NORMALISED_DIR, out_name)\n",
    "        else:\n",
    "            out_file = os.path.join(STITCHED_DIR, out_name)\n",
    "\n",
    "        if os.path.isfile(out_file):\n",
    "            if verbose:\n",
    "                print(f\"Out file already exists: {out_file}\")\n",
    "\n",
    "            if force:\n",
    "                if verbose:\n",
    "                    print(\"Force over-writing\")\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "        if normalise:\n",
    "            if verbose:\n",
    "                print(f\"Loading {picontrol_file}\")\n",
    "\n",
    "            picontrol_scmrun = netcdf_scm.io.load_scmrun(picontrol_file)\n",
    "            picontrol_scmrun.metadata[\"netcdf-scm crunched file\"] = picontrol_file\n",
    "\n",
    "            if climate_model == \"BCC-CSM2-MR\":\n",
    "                if verbose:\n",
    "                    print(\"Performing hack extension of piControl\")\n",
    "\n",
    "                picontrol_scmrun = get_bcc_csm2_mr_hack_extension(\n",
    "                    picontrol_scmrun, norm_years\n",
    "                )\n",
    "\n",
    "            elif climate_model == \"CAMS-CSM1-0\":\n",
    "                bt_raw = scmrun.metadata[\"(parent) branch_time_in_parent\"]\n",
    "                if verbose:\n",
    "                    print(\"Branch time in parent: {}\".format(bt_raw))\n",
    "                picontrol_branching_time = dt.datetime(int(bt_raw), 1, 1)\n",
    "                if verbose:\n",
    "                    print(\n",
    "                        \"Updating branch time to: {}\".format(picontrol_branching_time)\n",
    "                    )\n",
    "            elif climate_model in [\"FGOALS-f3-L\", \"CAS-ESM2-0\"]:\n",
    "                if climate_model == \"FGOALS-f3-L\":\n",
    "                    member_ids = {\n",
    "                        \"r1i1p1f1\": dt.datetime(600, 1, 1),\n",
    "                        \"r2i1p1f1\": dt.datetime(650, 1, 1),\n",
    "                        \"r3i1p1f1\": dt.datetime(700, 1, 1),\n",
    "                    }\n",
    "\n",
    "                elif climate_model == \"CAS-ESM2-0\":\n",
    "                    member_ids = {\n",
    "                        \"r1i1p1f1\": dt.datetime(100, 1, 1),\n",
    "                        \"r2i1p1f1\": dt.datetime(150, 1, 1),\n",
    "                        \"r3i1p1f1\": dt.datetime(200, 1, 1),\n",
    "                        \"r4i1p1f1\": dt.datetime(250, 1, 1),\n",
    "                    }\n",
    "\n",
    "                if verbose:\n",
    "                    print(\"Over-writing branch time metadata\")\n",
    "                picontrol_branching_time = member_ids[member_id]\n",
    "\n",
    "                if verbose:\n",
    "                    print(\"Assumed branch time: {}\".format(picontrol_branching_time))\n",
    "\n",
    "            elif climate_model == \"GFDL-CM4\":\n",
    "                assert (\n",
    "                    scmrun.metadata[\"(parent) parent_experiment_id\"] == \"piControl\"\n",
    "                ), scmrun.metadata[\"(parent) parent_experiment_id\"]\n",
    "                assert (\n",
    "                    scmrun.metadata[\"(parent) parent_time_units\"]\n",
    "                    == \"days since 0001-1-1\"\n",
    "                )\n",
    "                picontrol_branching_time = dt.datetime(\n",
    "                    picontrol_scmrun[\"year\"].min()\n",
    "                    - 1  # so that we start from zero (as confirmed via email)\n",
    "                    + picontrol_branching_time.year,\n",
    "                    picontrol_branching_time.month,\n",
    "                    picontrol_branching_time.day,\n",
    "                    picontrol_branching_time.hour,\n",
    "                )\n",
    "\n",
    "                if verbose:\n",
    "                    print(\"Assumed branch time: {}\".format(picontrol_branching_time))\n",
    "\n",
    "            elif climate_model == \"TaiESM1\":\n",
    "                source = netcdf_scm.io.load_scmrun(f)\n",
    "                parent_replacements = netcdf_scm.stitching.get_parent_replacements(\n",
    "                    source\n",
    "                )\n",
    "                parent_file = netcdf_scm.stitching.get_parent_file_path(\n",
    "                    f, parent_replacements, \"CMIP6Output\"\n",
    "                )\n",
    "                parent = netcdf_scm.io.load_scmrun(parent_file)\n",
    "                # email from group, they will fix later\n",
    "                parent.metadata[\"parent_time_units\"] = \"days since 0201-01-01\"\n",
    "                picontrol_branching_time = netcdf_scm.stitching.get_branch_time(parent)\n",
    "                if verbose:\n",
    "                    print(\"Assumed branch time: {}\".format(picontrol_branching_time))\n",
    "\n",
    "                if verbose:\n",
    "                    print(\"Performing hack extension of piControl\")\n",
    "\n",
    "                picontrol_scmrun = get_bcc_csm2_mr_hack_extension(\n",
    "                    picontrol_scmrun, norm_years\n",
    "                )\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"Normalising using {norm_years} years\")\n",
    "\n",
    "            normaliser = netcdf_scm.normalisation.NormaliserRunningMean(\n",
    "                nyears=norm_years\n",
    "            )\n",
    "\n",
    "            out = normaliser.normalise_against_picontrol(\n",
    "                scmrun, picontrol_scmrun, picontrol_branching_time\n",
    "            )\n",
    "        else:\n",
    "            out = scmrun\n",
    "\n",
    "        out[\"grid\"] = grid\n",
    "\n",
    "        out_to_disk = out.copy()\n",
    "        out_to_disk.metadata = {\n",
    "            k.replace(\"(\", \"\").replace(\")\", \"\"): v\n",
    "            for k, v in out_to_disk.metadata.items()\n",
    "        }\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Saving to {out_file}\")\n",
    "\n",
    "        out_to_disk.to_nc(out_file)\n",
    "\n",
    "        return None\n",
    "\n",
    "    if catch:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "\n",
    "            try:\n",
    "                return get_result()\n",
    "            except Exception as exc:\n",
    "                raise ValueError(\"File failed: {}\".format(f)) from exc\n",
    "    else:\n",
    "        return get_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-eligibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "checker = \"./20210416-country-crunch-popn-weighted/netcdf-scm-crunched/CMIP6/ScenarioMIP/MRI/MRI-ESM2-0/ssp534-over/r1i1p1f1/Amon/tas/gn/v20191108/netcdf-scm_tas_Amon_MRI-ESM2-0_ssp534-over_r1i1p1f1_gn_204001-230012.nc\"\n",
    "checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-extraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_CHECK = False\n",
    "%pdb off\n",
    "# %pdb on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-mailman",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CHECK:\n",
    "    import xarray as xr\n",
    "    from netcdf_scm.iris_cube_wrappers import ScmCube\n",
    "\n",
    "    def _load_helper_and_scm_cubes(path):\n",
    "        scm_cubes = {}\n",
    "\n",
    "        data = xr.open_dataset(path)\n",
    "        data.load()  # get everything in memory\n",
    "\n",
    "        # Must be kept until https://github.com/pandas-dev/pandas/issues/37071\n",
    "        # is solved\n",
    "        if data[\"time\"].encoding[\"units\"] == \"days since 1-01-01 00:00:00\":\n",
    "            data[\"time\"].encoding[\"units\"] = \"days since 0001-01-01 00:00:00\"\n",
    "\n",
    "        for _, darray in data.data_vars.items():\n",
    "            try:\n",
    "                region = darray.attrs[\"region\"]\n",
    "            except KeyError:\n",
    "                # bnds or some other unclassified variable\n",
    "                continue\n",
    "\n",
    "            if region != \"Nearest World\":\n",
    "                continue\n",
    "\n",
    "            scm_cubes[region] = ScmCube()\n",
    "\n",
    "            scm_cubes[region].cube = darray.to_iris()\n",
    "            scm_cubes[region].cube.attributes = {\n",
    "                **scm_cubes[region].cube.attributes,\n",
    "                **data.attrs,\n",
    "            }\n",
    "\n",
    "        # take any cube as base for now, not sure how to really handle this so will\n",
    "        # leave like this for now and only make this method public when I work it\n",
    "        # out...\n",
    "        loaded = list(scm_cubes.values())[0]\n",
    "\n",
    "        return loaded, scm_cubes\n",
    "\n",
    "    netcdf_scm.io._load_helper_and_scm_cubes = _load_helper_and_scm_cubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-alabama",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if RUN_CHECK:\n",
    "    tmp = stitch_and_normalise(checker, catch=False, verbose=True)\n",
    "    display(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-decline",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CHECK:\n",
    "    source = netcdf_scm.io.load_scmrun(checker)\n",
    "    display(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-objective",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CHECK:\n",
    "    parent_replacements = netcdf_scm.stitching.get_parent_replacements(source)\n",
    "    display(parent_replacements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "failing-northern",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CHECK:\n",
    "    parent_file = netcdf_scm.stitching.get_parent_file_path(\n",
    "        checker, parent_replacements, \"CMIP6Output\"\n",
    "    )\n",
    "    display(parent_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-arena",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CHECK:\n",
    "    parent = netcdf_scm.io.load_scmrun(parent_file)\n",
    "#     parent.metadata[\"parent_time_units\"] = \"days since 0001-01-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-manchester",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CHECK:\n",
    "    display(netcdf_scm.stitching.get_branch_time(parent, parent=True))\n",
    "    display(netcdf_scm.stitching.get_branch_time(parent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-disability",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CHECK:\n",
    "    !ncdump -h {parent_file} | grep parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-supplier",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CHECK:\n",
    "    picontrol = netcdf_scm.io.load_scmrun(\n",
    "        \"./country-crunch/netcdf-scm-crunched/CMIP6/CMIP/AS-RCEC/TaiESM1/piControl/r1i1p1f1/Amon/tas/gn/v20200211/netcdf-scm_tas_Amon_TaiESM1_piControl_r1i1p1f1_gn_020101-070012.nc\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-brunei",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CHECK:\n",
    "    display(picontrol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-oxford",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CHECK:\n",
    "    picontrol_new_time = picontrol.timeseries(time_axis=\"year-month\")\n",
    "    year_shift = 671 - 1850\n",
    "    # year_shift = 3030 - 1850\n",
    "    picontrol_new_time.columns = picontrol_new_time.columns.map(\n",
    "        lambda x: x - year_shift\n",
    "    )\n",
    "    # picontrol_new_time = picontrol_new_time.rolling(\n",
    "    #     window=21 * 12, center=True, axis=\"columns\"\n",
    "    # ).mean()\n",
    "    picontrol_new_time = scmdata.ScmRun(picontrol_new_time)\n",
    "    display(picontrol_new_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-negative",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CHECK:\n",
    "    ax = (\n",
    "        #         scmdata.run_append([source, parent, picontrol])\n",
    "        scmdata.run_append([source, parent, picontrol_new_time])\n",
    "        #         scmdata.run_append([source, parent, hack_extension])\n",
    "        .filter(region=\"World\", year=range(1840, 1855))  # .time_mean(\"AC\")\n",
    "        #     .filter(year=range(1850, 1950))\n",
    "        .lineplot(style=\"climate_model\")\n",
    "    )\n",
    "#     ax.set_xlim([1840, 1855])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amended-reservoir",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ssp_files = [f for f in ssp_files if \"MRI-ESM2\" in f]\n",
    "# ssp_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "static-station",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalise = False\n",
    "# normalise = True\n",
    "\n",
    "force = True\n",
    "force = False\n",
    "\n",
    "verbose = True\n",
    "verbose = False\n",
    "\n",
    "pool = ProcessPoolExecutor(max_workers=MAX_WORKERS)\n",
    "\n",
    "futures = []\n",
    "for f in tqdman.tqdm(ssp_files):\n",
    "    futures.append(\n",
    "        pool.submit(\n",
    "            stitch_and_normalise, f, normalise=normalise, verbose=verbose, force=force\n",
    "        )\n",
    "    )\n",
    "\n",
    "all_errors = []\n",
    "errors = []\n",
    "for i, future in tqdman.tqdm(\n",
    "    enumerate(as_completed(futures, timeout=None)), total=len(futures)\n",
    "):\n",
    "    try:\n",
    "        future.result()\n",
    "    except Exception as exc:\n",
    "        errors.append(traceback.format_exc())\n",
    "\n",
    "    if i % 50 == 10 or i == len(futures) - 1:\n",
    "        print(\"\\n\\n\".join(errors))\n",
    "        all_errors += list(\n",
    "            set([v for e in errors for v in re.findall(\".*File failed: (.*.nc)\", e)])\n",
    "        )\n",
    "        #         if errors:\n",
    "        #             break\n",
    "        errors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-village",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moral-thread",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_errors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
